{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Theory of Learning Under Class Imbalance - Full Experiment Suite\n",
    "\n",
    "This notebook runs all experiments and generates all figures for the paper **\"A Geometric Theory of Learning Under Class Imbalance\"**.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We validate the following key claims:\n",
    "1. Under label shift, only threshold/logit-offset updates are needed (no retraining)\n",
    "2. Ranking metrics (AUC) are invariant under prevalence changes  \n",
    "3. Reweighting/rebalancing reduces effective sample size and increases instability\n",
    "4. Under concept drift, offset alone fails and retraining is necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add package to path\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Import our modules\n",
    "from src.geomimb.utils.logging import setup_logging\n",
    "from src.geomimb.utils.io import ensure_output_dirs, save_metadata\n",
    "from src.geomimb.utils.checks import run_all_checks\n",
    "from src.geomimb.plotting.plots import create_all_experiment_plots\n",
    "\n",
    "# Import all experiments\n",
    "from src.geomimb.experiments.exp1_label_shift_offset import run_experiment as run_exp1\n",
    "from src.geomimb.experiments.exp2_auc_invariance import run_experiment as run_exp2\n",
    "from src.geomimb.experiments.exp3_weighting_neff_instability import run_experiment as run_exp3\n",
    "from src.geomimb.experiments.exp4_operating_point_metrics import run_experiment as run_exp4\n",
    "from src.geomimb.experiments.exp5_concept_drift_control import run_experiment as run_exp5\n",
    "\n",
    "# Setup\n",
    "setup_logging(level='INFO')\n",
    "ensure_output_dirs()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key configuration parameters\n",
    "from src.geomimb import config\n",
    "\n",
    "print(\"Experiment Configuration:\")\n",
    "print(f\"- Training prevalence: {config.PI_TRAIN}\")\n",
    "print(f\"- Test prevalences: {config.PI_TEST_GRID}\")\n",
    "print(f\"- Cost settings: {config.COSTS_GRID}\")\n",
    "print(f\"- Number of seeds: {len(config.SEEDS)}\")\n",
    "print(f\"- Synthetic dimension: {config.SYNTH_DIM}\")\n",
    "print(f\"- Alpha values (Exp 3): {config.ALPHA_VALUES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Generation Preview\n",
    "\n",
    "Let's visualize the synthetic data generation process to understand the Gaussian mixture model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview synthetic data\n",
    "from src.geomimb.data.synthetic import sample_synthetic_dataset, get_synthetic_params\n",
    "\n",
    "# Get parameters\n",
    "params = get_synthetic_params()\n",
    "print(\"Synthetic Data Parameters:\")\n",
    "print(f\"- Dimension: {params['d']}\")\n",
    "print(f\"- mu0 (class 0): {params['mu0'][:5]}... (first 5 dims)\")\n",
    "print(f\"- mu1 (class 1): {params['mu1'][:5]}... (first 5 dims)\")\n",
    "print(f\"- Theoretical LLR coefficient: {params['theoretical_llr_coef'][:5]}...\")\n",
    "print(f\"- Theoretical LLR constant: {params['theoretical_llr_const']:.3f}\")\n",
    "\n",
    "# Sample and visualize\n",
    "X_sample, y_sample = sample_synthetic_dataset(pi=0.3, n=1000, seed=42)\n",
    "\n",
    "# Plot first two discriminative dimensions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Dimension 0 (discriminative)\n",
    "ax1.hist(X_sample[y_sample==0, 0], bins=30, alpha=0.5, label='Class 0', density=True)\n",
    "ax1.hist(X_sample[y_sample==1, 0], bins=30, alpha=0.5, label='Class 1', density=True)\n",
    "ax1.set_xlabel('Feature 0 (discriminative)')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.legend()\n",
    "ax1.set_title('First Discriminative Dimension')\n",
    "\n",
    "# Dimension 5 (non-discriminative)\n",
    "ax2.hist(X_sample[y_sample==0, 5], bins=30, alpha=0.5, label='Class 0', density=True)\n",
    "ax2.hist(X_sample[y_sample==1, 5], bins=30, alpha=0.5, label='Class 1', density=True)\n",
    "ax2.set_xlabel('Feature 5 (non-discriminative)')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.legend()\n",
    "ax2.set_title('Non-Discriminative Dimension')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Base Model and Verify Implementation\n",
    "\n",
    "Before running full experiments, let's verify our implementation with a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single model and check coefficients\n",
    "from src.geomimb.models.sklearn_models import LogisticRegressionWrapper\n",
    "from src.geomimb.seeds import set_global_seed\n",
    "\n",
    "set_global_seed(0)\n",
    "\n",
    "# Generate training data\n",
    "X_train, y_train = sample_synthetic_dataset(pi=0.2, n=10000, seed=0)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegressionWrapper(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get coefficients\n",
    "coef = model.get_coefficients()\n",
    "intercept = model.get_intercept()\n",
    "\n",
    "print(\"Trained Logistic Regression:\")\n",
    "print(f\"- Coefficients (first 5): {coef[:5]}\")\n",
    "print(f\"- Coefficients (last 5): {coef[-5:]}\")\n",
    "print(f\"- Intercept: {intercept:.3f}\")\n",
    "\n",
    "# Compare with theoretical\n",
    "theoretical_coef = params['theoretical_llr_coef']\n",
    "cosine_sim = np.dot(coef, theoretical_coef) / (np.linalg.norm(coef) * np.linalg.norm(theoretical_coef))\n",
    "print(f\"\\nCosine similarity to theoretical: {cosine_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Threshold Selection Function\n",
    "\n",
    "Verify our precision-constrained threshold selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test threshold selection with synthetic arrays\n",
    "from src.geomimb.metrics.calibration import tune_threshold_for_operating_point\n",
    "\n",
    "# Create synthetic scores and labels\n",
    "np.random.seed(42)\n",
    "n_test = 1000\n",
    "y_test = np.random.binomial(1, 0.3, n_test)\n",
    "scores = np.random.randn(n_test) + y_test * 1.5  # Shifted scores for class 1\n",
    "\n",
    "# Find threshold for precision >= 0.95\n",
    "threshold, info = tune_threshold_for_operating_point(\n",
    "    scores, y_test, \n",
    "    target_metric='precision', \n",
    "    target_value=0.95,\n",
    "    constraint_type='min',\n",
    "    optimize_metric='recall'\n",
    ")\n",
    "\n",
    "print(f\"Found threshold: {threshold:.3f}\")\n",
    "print(f\"Feasible: {info['feasible']}\")\n",
    "print(f\"Best recall at precision >= 0.95: {info['best_recall']:.3f}\")\n",
    "\n",
    "# Verify by computing metrics at this threshold\n",
    "from src.geomimb.metrics.classification import apply_threshold, compute_metrics\n",
    "y_pred = apply_threshold(scores, threshold)\n",
    "metrics = compute_metrics(y_test, y_pred)\n",
    "print(f\"\\nActual metrics at threshold:\")\n",
    "print(f\"- Precision: {metrics['precision']:.3f}\")\n",
    "print(f\"- Recall: {metrics['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Experiment 1: Label Shift Offset Correction\n",
    "\n",
    "This experiment validates that under label shift, offset correction works and retraining is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Running Experiment 1: Label Shift Offset Correction\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "exp1_results = run_exp1(dataset_name='both', save_results=True)\n",
    "\n",
    "print(f\"\\nCompleted with {len(exp1_results)} results\")\n",
    "\n",
    "# Show summary\n",
    "summary = exp1_results.groupby(['dataset', 'method', 'pi_test']).agg({\n",
    "    'auc': ['mean', 'std'],\n",
    "    'risk': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nAUC by method and prevalence (first dataset):\")\n",
    "print(summary.loc['synthetic', :, 'auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Experiment 2: AUC Invariance\n",
    "\n",
    "This experiment demonstrates that AUC is invariant to prevalence while PR-AUC depends on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Running Experiment 2: AUC Invariance\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "exp2_results = run_exp2(dataset_name='both', save_results=True)\n",
    "\n",
    "print(f\"\\nCompleted with {len(exp2_results)} results\")\n",
    "\n",
    "# Check AUC invariance\n",
    "for (dataset, model), group in exp2_results.groupby(['dataset', 'model']):\n",
    "    auc_range = group['auc'].max() - group['auc'].min()\n",
    "    pr_auc_range = group['pr_auc'].max() - group['pr_auc'].min()\n",
    "    print(f\"\\n{dataset} - {model}:\")\n",
    "    print(f\"  AUC range: {auc_range:.4f}\")\n",
    "    print(f\"  PR-AUC range: {pr_auc_range:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Experiment 3: Weighting Reduces Neff and Increases Instability\n",
    "\n",
    "This experiment shows that class weighting reduces effective sample size and increases model instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Running Experiment 3: Weighting Neff and Instability\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "exp3_results = run_exp3(dataset_name='both', save_results=True)\n",
    "\n",
    "print(f\"\\nCompleted with {len(exp3_results)} results\")\n",
    "\n",
    "# Show Neff by alpha\n",
    "neff_summary = exp3_results.groupby(['dataset', 'alpha'])['neff'].mean().round(0)\n",
    "print(\"\\nEffective sample size by alpha:\")\n",
    "print(neff_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run Experiment 4: Operating Point Metrics\n",
    "\n",
    "This experiment shows that operating point metrics drift without correction but are restored with offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Running Experiment 4: Operating Point Metrics\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "exp4_results = run_exp4(save_results=True)\n",
    "\n",
    "print(f\"\\nCompleted with {len(exp4_results)} results\")\n",
    "\n",
    "# Show precision/recall drift\n",
    "for method in ['nocorr', 'offset']:\n",
    "    method_data = exp4_results[exp4_results['method'] == method]\n",
    "    prec_by_pi = method_data.groupby('pi_test')['precision'].mean()\n",
    "    print(f\"\\n{method} - Precision by prevalence:\")\n",
    "    print(prec_by_pi.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Experiment 5: Concept Drift Control\n",
    "\n",
    "This experiment demonstrates that under concept drift, offset doesn't help but retraining does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Running Experiment 5: Concept Drift Control\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "exp5_results = run_exp5(save_results=True)\n",
    "\n",
    "print(f\"\\nCompleted with {len(exp5_results)} results\")\n",
    "\n",
    "# Show performance by method\n",
    "perf_summary = exp5_results.groupby('method')[['auc', 'risk']].mean().round(3)\n",
    "print(\"\\nPerformance under concept drift:\")\n",
    "print(perf_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Run All Acceptance Checks\n",
    "\n",
    "Verify that all experiments meet the acceptance criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "all_results = {\n",
    "    'exp1': exp1_results,\n",
    "    'exp2': exp2_results,\n",
    "    'exp3': exp3_results,\n",
    "    'exp4': exp4_results,\n",
    "    'exp5': exp5_results\n",
    "}\n",
    "\n",
    "# Run acceptance checks\n",
    "checks = run_all_checks(all_results)\n",
    "\n",
    "print(\"Acceptance Check Results:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for check_name, check_result in checks.items():\n",
    "    if check_name == 'overall_passed':\n",
    "        continue\n",
    "    \n",
    "    passed = check_result.get('passed', True)\n",
    "    status = \"✓ PASSED\" if passed else \"✗ FAILED\"\n",
    "    print(f\"{check_name}: {status}\")\n",
    "    \n",
    "    if not passed and 'violations' in check_result:\n",
    "        print(f\"  Violations: {len(check_result['violations'])}\")\n",
    "        # Show first violation\n",
    "        if check_result['violations']:\n",
    "            print(f\"  Example: {check_result['violations'][0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "overall = \"✓ ALL CHECKS PASSED\" if checks['overall_passed'] else \"✗ SOME CHECKS FAILED\"\n",
    "print(f\"Overall: {overall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Generate All Plots\n",
    "\n",
    "Create all figures for the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all plots\n",
    "print(\"Generating all plots...\")\n",
    "create_all_experiment_plots(all_results)\n",
    "print(\"All plots saved to outputs/figures/\")\n",
    "\n",
    "# Display a few key plots inline\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "key_plots = [\n",
    "    'exp1_auc_vs_pi.png',\n",
    "    'exp1_risk_vs_pi.png', \n",
    "    'exp3_neff_vs_alpha.png',\n",
    "    'exp5_concept_drift.png'\n",
    "]\n",
    "\n",
    "for plot_file in key_plots:\n",
    "    plot_path = f'../outputs/figures/{plot_file}'\n",
    "    if os.path.exists(plot_path):\n",
    "        print(f\"\\n{plot_file}:\")\n",
    "        display(Image(plot_path, width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Create Paper Summary Table\n",
    "\n",
    "Generate the final summary table for the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.geomimb.utils.io import create_paper_summary\n",
    "\n",
    "# Combine all results\n",
    "combined_results = pd.concat(list(all_results.values()), ignore_index=True)\n",
    "\n",
    "# Create summary\n",
    "summary_df = create_paper_summary(combined_results)\n",
    "\n",
    "print(\"Paper Summary Table:\")\n",
    "print(summary_df.to_string())\n",
    "\n",
    "# Also save as LaTeX\n",
    "latex_table = summary_df.to_latex(index=False, float_format=\"%.3f\")\n",
    "with open('../outputs/tables/paper_summary.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(\"\\nLaTeX table saved to outputs/tables/paper_summary.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Summary\n",
    "\n",
    "Summarize the key findings that support the paper's claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EXPERIMENT SUITE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Key findings\n",
    "print(\"\\nKey Findings:\")\n",
    "\n",
    "# 1. AUC invariance\n",
    "auc_check = checks.get('exp1_auc_invariance', {})\n",
    "if auc_check.get('passed', False):\n",
    "    print(\"✓ AUC is invariant to prevalence changes (max range < 0.01)\")\n",
    "\n",
    "# 2. Offset improvement\n",
    "offset_check = checks.get('exp1_offset_improvement', {})\n",
    "if offset_check.get('passed', False):\n",
    "    print(\"✓ Offset correction reduces risk at extreme imbalance\")\n",
    "\n",
    "# 3. Neff monotonicity\n",
    "neff_check = checks.get('exp3_neff_monotonicity', {})\n",
    "if neff_check.get('passed', False):\n",
    "    print(\"✓ Weighting monotonically reduces effective sample size\")\n",
    "\n",
    "# 4. Concept drift\n",
    "drift_check = checks.get('exp5_concept_drift', {})\n",
    "if drift_check.get('passed', False):\n",
    "    print(\"✓ Under concept drift, offset fails but retraining helps\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All experiments completed successfully!\")\n",
    "print(f\"Results saved in: outputs/\")\n",
    "print(f\"- Tables: outputs/tables/\")\n",
    "print(f\"- Figures: outputs/figures/\")\n",
    "print(f\"- Metadata: outputs/metadata/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}